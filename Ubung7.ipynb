{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решить задачу классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(os.path.join('..', '..', 'data', 'ForUbung', 'neo_task.csv'))\n",
    "\n",
    "x = lambda x: x.mean() if x.notna().any() else 0\n",
    "group = df.groupby('miss_distance')['relative_velocity'].transform('mean').iat[0]\n",
    "df['relative_velocity'].fillna(group, inplace=True)\n",
    "\n",
    "x = lambda x: x.median() if x.notna().any() else 0\n",
    "group = df.groupby('est_diameter_min')['absolute_magnitude'].transform(x)\n",
    "df['absolute_magnitude'].fillna(group, inplace=True)\n",
    "\n",
    "table = df['est_diameter_max'] - df['est_diameter_min']\n",
    "df['est_diameter_max'].fillna(df['est_diameter_min'] + table.mean(), inplace=True)\n",
    "\n",
    "df['name'].fillna('0 unknow', inplace=True)\n",
    "\n",
    "df['id'].fillna(df['id'].mode()[1], inplace=True)\n",
    "\n",
    "df.loc[df['absolute_magnitude'] == 0]\n",
    "df = df.drop(index=df.loc[df['absolute_magnitude'] == 0].index)\n",
    "\n",
    "dict_patch = {\n",
    "    False: 0,\n",
    "    True: 1\n",
    "}\n",
    "df['hazardous'] = df['hazardous'].map(dict_patch)\n",
    "\n",
    "X = df.drop(['name', 'hazardous', 'est_diameter_max'], axis=1)\n",
    "Y = df['hazardous']\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_resampled, y_resampled = rus.fit_resample(X, Y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, train_size=0.2, random_state=42, stratify=y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3536, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      7072\n",
      "           1       0.50      1.00      0.67      7072\n",
      "\n",
      "    accuracy                           0.50     14144\n",
      "   macro avg       0.25      0.50      0.33     14144\n",
      "weighted avg       0.25      0.50      0.33     14144\n",
      "\n",
      "[[   0 7072]\n",
      " [   0 7072]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ktulu\\OneDrive\\Документы\\ML - лабы\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ktulu\\OneDrive\\Документы\\ML - лабы\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ktulu\\OneDrive\\Документы\\ML - лабы\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_classification_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\", input_shape=(5, )),\n",
    "    ]\n",
    ")\n",
    "w0 = 1 / y_train[y_train==0].shape[0]\n",
    "w1 = 1 / y_train[y_train==1].shape[0]\n",
    "\n",
    "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"binary_crossentropy\")\n",
    "\n",
    "model_classification_1.fit(X_train, y_train, epochs=50, verbose=None, class_weight={0: w0, 1: w1})\n",
    "\n",
    "y_pred = np.around(model_classification_1.predict(X_test, verbose=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.27      0.40      7072\n",
      "           1       0.56      0.92      0.70      7072\n",
      "\n",
      "    accuracy                           0.60     14144\n",
      "   macro avg       0.67      0.60      0.55     14144\n",
      "weighted avg       0.67      0.60      0.55     14144\n",
      "\n",
      "[[1922 5150]\n",
      " [ 533 6539]]\n"
     ]
    }
   ],
   "source": [
    "model_classification_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(5,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        # используем 1 нейрон и sigmoid\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"binary_crossentropy\")\n",
    "model_classification_1.fit(X_train, y_train, epochs=25, verbose=None,\n",
    "                           class_weight={0: w0, 1: w1})\n",
    "y_pred = np.around(model_classification_1.predict(X_test, verbose=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решить задачу регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('..', '..', 'data', 'ForUbung', 'trip_duration_task.csv'))\n",
    "\n",
    "df['vendor_id'] = df['vendor_id'].fillna(1)\n",
    "df['vendor_id'] = df['vendor_id'].astype(int)\n",
    "\n",
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime']).map(pd.Timestamp.timestamp)\n",
    "df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime']).map(pd.Timestamp.timestamp)\n",
    "\n",
    "group = df.groupby('dropoff_latitude')['pickup_latitude'].transform('median').median()\n",
    "df['pickup_latitude'] = df['pickup_latitude'].fillna(group)\n",
    "\n",
    "null_passeger = df.loc[df['passenger_count'] == 0]\n",
    "\n",
    "df = df.drop(index=null_passeger.index)\n",
    "\n",
    "del_latidute = (np.pi / 180) * (df['dropoff_latitude'] - df['pickup_latitude'])\n",
    "mean_latidude = (df['dropoff_latitude'] + df['pickup_latitude']) / 2\n",
    "del_longitude = (np.pi / 180) * (df['dropoff_longitude'] - df['pickup_longitude'])\n",
    "\n",
    "distance = pd.DataFrame(6371 * np.sqrt(np.power(del_latidute, 2) + np.power(np.cos(mean_latidude) * del_longitude, 2)))\n",
    "df['distance'] = distance\n",
    "\n",
    "df['id'] = df['id'].transform(lambda x: x.str[2:]).astype(int)\n",
    "\n",
    "\n",
    "X = df.drop('trip_duration', axis=1)\n",
    "Y = df[['trip_duration']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11396/11396 [==============================] - 15s 1ms/step - loss: 939326393286656.0000\n",
      "11396/11396 [==============================] - 13s 1ms/step\n",
      "10938.52220197673\n",
      "11396/11396 [==============================] - 13s 1ms/step\n",
      "147815076.99745306\n"
     ]
    }
   ],
   "source": [
    "model_regression = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")\n",
    "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")\n",
    "\n",
    "model_regression.fit(X_train, y_train)\n",
    "\n",
    "print(mean_absolute_error(y_test, model_regression.predict(X_test)))\n",
    "print(mean_squared_error(y_test, model_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364644, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11396/11396 [==============================] - 20s 2ms/step - loss: 12002429763584.0000\n",
      "11396/11396 [==============================] - 15s 1ms/step\n",
      "948.1718471035038\n",
      "11396/11396 [==============================] - 15s 1ms/step\n",
      "10617664.17287037\n"
     ]
    }
   ],
   "source": [
    "model_regression = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(10,)),\n",
    "        tf.keras.layers.Dense(32, activation=\"linear\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11396/11396 [==============================] - 16s 1ms/step\n",
      "555.3080880271689\n",
      "11396/11396 [==============================] - 16s 1ms/step\n",
      "9799636.745708058\n"
     ]
    }
   ],
   "source": [
    "model_regression.fit(X_train, y_train, epochs=10, verbose=None)\n",
    "\n",
    "print(mean_absolute_error(y_test, model_regression.predict(X_test)))\n",
    "print(mean_squared_error(y_test, model_regression.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
